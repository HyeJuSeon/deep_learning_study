{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab10 - ReLU, Xavier, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax\n",
    "\n",
    "다른 reshape 방법\n",
    "\n",
    "``` python \n",
    "model.add(tf.keras.layers.Flatten(input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0411 - accuracy: 0.9979\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 7.8394e-04 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.4242e-04 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.7906e-04 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.8721e-04 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.3041e-04 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 9.3084e-05 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 6.7529e-05 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.9576e-05 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 3.6704e-05 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.7316e-05 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.0422e-05 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.5313e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 1.1507e-05 - accuracy: 1.0000\n",
      "Prediction: \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "313/313 [==============================] - 0s 911us/step - loss: 5006.8130 - accuracy: 0.0980\n",
      "Accuracy:  0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# nomalizing data\n",
    "x_train, y_train = x_train / 255.0, y_train / 255.0\n",
    "\n",
    "# change data shape\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "# change result to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=10, input_dim=784, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "predictions = tf.model.predict(x_test)\n",
    "print(\"Prediction: \\n\", predictions)\n",
    "score = tf.model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1774 - accuracy: 0.8935\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4389 - accuracy: 0.9424\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2867 - accuracy: 0.9559\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2185 - accuracy: 0.9620\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1788 - accuracy: 0.9670\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1512 - accuracy: 0.9707\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1393 - accuracy: 0.9731\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1177 - accuracy: 0.9746\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0980 - accuracy: 0.9782\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0797 - accuracy: 0.9802\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0763 - accuracy: 0.9809\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0844 - accuracy: 0.9789\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0731 - accuracy: 0.9817\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0656 - accuracy: 0.9827\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9833\n",
      "index:  6311 actual y:  2 predicted y:  2\n",
      "index:  6890 actual y:  4 predicted y:  4\n",
      "index:  663 actual y:  1 predicted y:  1\n",
      "index:  4242 actual y:  3 predicted y:  3\n",
      "index:  8376 actual y:  1 predicted y:  1\n",
      "index:  7961 actual y:  8 predicted y:  8\n",
      "index:  6634 actual y:  1 predicted y:  1\n",
      "index:  4969 actual y:  2 predicted y:  2\n",
      "index:  7808 actual y:  5 predicted y:  5\n",
      "index:  5866 actual y:  7 predicted y:  7\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9569\n",
      "loss:  0.2278946340084076\n",
      "accuracy:  0.9569000005722046\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test2, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], x_test2.shape[1] * x_test2.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, input_dim=784, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test2)\n",
    "for x in range(10):\n",
    "    random_index = random.randint(0, x_test2.shape[0] - 1)\n",
    "    print(\"index: \", random_index,\n",
    "          \"actual y: \", np.argmax(y_test[random_index]),\n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "          \n",
    "evaluation = tf.model.evaluate(x_test2, y_test)\n",
    "print(\"loss: \", evaluation[0])\n",
    "print(\"accuracy: \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN using xavier\n",
    "\n",
    "initialize weight\n",
    "\n",
    "kernel_initialize 종류:  https://keras.io/api/layers/initializers/\n",
    "\n",
    "xavier를 사용하면 처음부터 cost가 낮다. 이는 초기값이 잘 초기화 된다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2404 - accuracy: 0.8929\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3918 - accuracy: 0.9417\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2516 - accuracy: 0.9561\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1910 - accuracy: 0.9630\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1696 - accuracy: 0.9676\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1415 - accuracy: 0.9710\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1156 - accuracy: 0.9746\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1026 - accuracy: 0.9760\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1031 - accuracy: 0.9764\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0874 - accuracy: 0.9786\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0805 - accuracy: 0.9795\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0668 - accuracy: 0.9817\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0775 - accuracy: 0.9814\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0792 - accuracy: 0.9802\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0698 - accuracy: 0.9821\n",
      "index:  6311 actual y:  2 predicted y:  2\n",
      "index:  6890 actual y:  4 predicted y:  4\n",
      "index:  663 actual y:  1 predicted y:  1\n",
      "index:  4242 actual y:  3 predicted y:  3\n",
      "index:  8376 actual y:  1 predicted y:  1\n",
      "index:  7961 actual y:  8 predicted y:  8\n",
      "index:  6634 actual y:  1 predicted y:  1\n",
      "index:  4969 actual y:  2 predicted y:  2\n",
      "index:  7808 actual y:  5 predicted y:  5\n",
      "index:  5866 actual y:  7 predicted y:  7\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9709\n",
      "loss:  0.18017250299453735\n",
      "accuracy:  0.9708999991416931\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, input_dim=784, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(10):\n",
    "    random_index = random.randint(0, x_test.shape[0] - 1)\n",
    "    print(\"index: \", random_index,\n",
    "          \"actual y: \", np.argmax(y_test[random_index]),\n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "    \n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", evaluation[0])\n",
    "print(\"accuracy: \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 1.0557 - accuracy: 0.9042\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.1331 - accuracy: 0.9600\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1108 - accuracy: 0.9676\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0887 - accuracy: 0.9728\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0843 - accuracy: 0.9751\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0742 - accuracy: 0.9784\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0721 - accuracy: 0.9783\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0666 - accuracy: 0.9811\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0565 - accuracy: 0.9836\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0588 - accuracy: 0.9839 0s - loss: 0.0587 - accuracy: 0.\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0500 - accuracy: 0.9859\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.0455 - accuracy: 0.9876\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0549 - accuracy: 0.9851\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0484 - accuracy: 0.9876\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0413 - accuracy: 0.9886\n",
      "index:  6311 actual y:  2 predicted y:  2\n",
      "index:  6890 actual y:  4 predicted y:  4\n",
      "index:  663 actual y:  1 predicted y:  1\n",
      "index:  4242 actual y:  3 predicted y:  3\n",
      "index:  8376 actual y:  1 predicted y:  1\n",
      "index:  7961 actual y:  8 predicted y:  8\n",
      "index:  6634 actual y:  1 predicted y:  1\n",
      "index:  4969 actual y:  2 predicted y:  2\n",
      "index:  7808 actual y:  5 predicted y:  5\n",
      "index:  5866 actual y:  7 predicted y:  7\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1436 - accuracy: 0.9723\n",
      "loss:  0.14364789426326752\n",
      "accuracy:  0.9722999930381775\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, input_dim=784, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(10):\n",
    "    random_index = random.randint(0, x_test.shape[0] - 1)\n",
    "    print(\"index: \", random_index, \n",
    "          \"actual y: \", np.argmax(y_test[random_index]), \n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "    \n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", evaluation[0])\n",
    "print(\"accuracy: \", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,770,954\n",
      "Trainable params: 2,770,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.3954 - accuracy: 0.90130s - loss: 0.3964 - accuracy: 0.\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.1435 - accuracy: 0.9621\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.1126 - accuracy: 0.9710\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0937 - accuracy: 0.9755\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.0961 - accuracy: 0.9769\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.0871 - accuracy: 0.9797\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0777 - accuracy: 0.9819\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 18s 31ms/step - loss: 0.0657 - accuracy: 0.9847\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 18s 31ms/step - loss: 0.0727 - accuracy: 0.9841\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.0806 - accuracy: 0.9835\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.0622 - accuracy: 0.9859\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0633 - accuracy: 0.9862\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0600 - accuracy: 0.9876\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0579 - accuracy: 0.9875\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.0402 - accuracy: 0.9914\n",
      "index:  6311 actual y:  2 predicted y:  2\n",
      "index:  6890 actual y:  4 predicted y:  4\n",
      "index:  663 actual y:  1 predicted y:  1\n",
      "index:  4242 actual y:  3 predicted y:  3\n",
      "index:  8376 actual y:  1 predicted y:  1\n",
      "index:  7961 actual y:  8 predicted y:  8\n",
      "index:  6634 actual y:  1 predicted y:  1\n",
      "index:  4969 actual y:  2 predicted y:  2\n",
      "index:  7808 actual y:  5 predicted y:  5\n",
      "index:  5866 actual y:  7 predicted y:  7\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9771\n",
      "loss:  0.15194597840309143\n",
      "accuracy:  0.9771000146865845\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, input_dim=784, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(10):\n",
    "    random_index = random.randint(0, x_test.shape[0] - 1)\n",
    "    print(\"index: \", random_index, \n",
    "          \"actual y: \", np.argmax(y_test[random_index]), \n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "    \n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", evaluation[0])\n",
    "print(\"accuracy: \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 9s 14ms/step - loss: 1.9251 - accuracy: 0.7666\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.3696 - accuracy: 0.8963\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 9s 14ms/step - loss: 0.2737 - accuracy: 0.9235\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.2304 - accuracy: 0.9373\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.2035 - accuracy: 0.9441\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1933 - accuracy: 0.9479\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1868 - accuracy: 0.9511\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.1829 - accuracy: 0.9528\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1821 - accuracy: 0.9538\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1844 - accuracy: 0.9549\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1803 - accuracy: 0.9556\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1689 - accuracy: 0.9589\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1707 - accuracy: 0.9585\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.1645 - accuracy: 0.9607\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1811 - accuracy: 0.9592\n",
      "index:  6311 actual y:  2 predicted y:  2\n",
      "index:  6890 actual y:  4 predicted y:  4\n",
      "index:  663 actual y:  1 predicted y:  1\n",
      "index:  4242 actual y:  3 predicted y:  3\n",
      "index:  8376 actual y:  1 predicted y:  1\n",
      "index:  7961 actual y:  8 predicted y:  8\n",
      "index:  6634 actual y:  1 predicted y:  1\n",
      "index:  4969 actual y:  2 predicted y:  2\n",
      "index:  7808 actual y:  5 predicted y:  5\n",
      "index:  5866 actual y:  7 predicted y:  7\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1280 - accuracy: 0.9708\n",
      "loss:  0.1279703676700592\n",
      "accuracy:  0.97079998254776\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "drop_rate = 0.3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, input_dim=784, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(10):\n",
    "    random_index = random.randint(0, x_test.shape[0] - 1)\n",
    "    print(\"index: \", random_index, \n",
    "          \"actual y: \", np.argmax(y_test[random_index]), \n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "    \n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", evaluation[0])\n",
    "print(\"accuracy: \", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,770,954\n",
      "Trainable params: 2,770,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 1.8429 - accuracy: 0.3938\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.4452 - accuracy: 0.8850\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.3131 - accuracy: 0.9275\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.2671 - accuracy: 0.9402\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.2371 - accuracy: 0.9463\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.2296 - accuracy: 0.9507\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.2198 - accuracy: 0.9541\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.2236 - accuracy: 0.9543\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.2221 - accuracy: 0.9554\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.2099 - accuracy: 0.9578\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.1976 - accuracy: 0.9600\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.2046 - accuracy: 0.9590\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.1972 - accuracy: 0.9593\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 0.2024 - accuracy: 0.9595\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.2101 - accuracy: 0.9576\n",
      "index:  6311 actual y:  2 predicted y:  2\n",
      "index:  6890 actual y:  4 predicted y:  4\n",
      "index:  663 actual y:  1 predicted y:  1\n",
      "index:  4242 actual y:  3 predicted y:  3\n",
      "index:  8376 actual y:  1 predicted y:  1\n",
      "index:  7961 actual y:  8 predicted y:  8\n",
      "index:  6634 actual y:  1 predicted y:  1\n",
      "index:  4969 actual y:  2 predicted y:  2\n",
      "index:  7808 actual y:  5 predicted y:  5\n",
      "index:  5866 actual y:  7 predicted y:  7\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2238 - accuracy: 0.9711\n",
      "loss:  0.22384755313396454\n",
      "accuracy:  0.9710999727249146\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "drop_rate = 0.3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, input_dim=784, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(10):\n",
    "    random_index = random.randint(0, x_test.shape[0] - 1)\n",
    "    print(\"index: \", random_index, \n",
    "          \"actual y: \", np.argmax(y_test[random_index]), \n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "    \n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", evaluation[0])\n",
    "print(\"accuracy: \", evaluation[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
